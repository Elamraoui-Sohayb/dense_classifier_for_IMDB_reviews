{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we build a dense neural net to classify IMDB movie reviews by their sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# the dataset\n",
    "from keras.datasets import imdb\n",
    "# for sequence padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# model type: sequential\n",
    "from keras.models import Sequential\n",
    "# usual layers\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "# for NLP, embedding layer\n",
    "from keras.layers import Embedding # new!\n",
    "# saving the results frm each epoch\n",
    "from keras.callbacks import ModelCheckpoint # new! \n",
    "import os # new! \n",
    "# using the ROC_AUC as a metric \n",
    "from sklearn.metrics import roc_auc_score, roc_curve # new!\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # new!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory name:\n",
    "output_dir = 'model_output/dense'\n",
    "\n",
    "# training:\n",
    "epochs = 4\n",
    "batch_size = 128 #the mini batchsize for gradient descent\n",
    "\n",
    "# vector-space embedding: \n",
    "n_dim = 64\n",
    "n_unique_words = 5000 # as per Maas et al. (2011); may not be optimal\n",
    "n_words_to_skip = 50 # ditto; the most commun words to skip\n",
    "max_review_length = 100 # if the review has more it will be truncated\n",
    "pad_type = trunc_type = 'pre' # if less than 100, the review should be padded, 'pre'= operating at the begining; either in truncating or padding\n",
    "\n",
    "# neural network architecture: 1 dense layer, 64 neurons at the begining, droping out half\n",
    "n_dense = 64\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given data set: \n",
    "\n",
    "* the Keras text utilities [here](https://keras.io/preprocessing/text/) quickly preprocess natural language and convert it into an index\n",
    "* the `keras.preprocessing.text.Tokenizer` class may do everything you need in one line:\n",
    "    * tokenize into words or characters\n",
    "    * `num_words`: maximum unique tokens\n",
    "    * filter out punctuation\n",
    "    * lower case\n",
    "    * convert words to an integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 18s    \n"
     ]
    }
   ],
   "source": [
    "# valid==test, a good point made by the author about the ditinction between test and validation\n",
    "(x_train, y_train), (x_valid, y_valid) = imdb.load_data(num_words=n_unique_words, skip_top=n_words_to_skip) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ list([2, 2, 2, 2, 2, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 2, 173, 2, 256, 2, 2, 100, 2, 838, 112, 50, 670, 2, 2, 2, 480, 284, 2, 150, 2, 172, 112, 167, 2, 336, 385, 2, 2, 172, 4536, 1111, 2, 546, 2, 2, 447, 2, 192, 50, 2, 2, 147, 2025, 2, 2, 2, 2, 1920, 4613, 469, 2, 2, 71, 87, 2, 2, 2, 530, 2, 76, 2, 2, 1247, 2, 2, 2, 515, 2, 2, 2, 626, 2, 2, 2, 62, 386, 2, 2, 316, 2, 106, 2, 2, 2223, 2, 2, 480, 66, 3785, 2, 2, 130, 2, 2, 2, 619, 2, 2, 124, 51, 2, 135, 2, 2, 1415, 2, 2, 2, 2, 215, 2, 77, 52, 2, 2, 407, 2, 82, 2, 2, 2, 107, 117, 2, 2, 256, 2, 2, 2, 3766, 2, 723, 2, 71, 2, 530, 476, 2, 400, 317, 2, 2, 2, 2, 1029, 2, 104, 88, 2, 381, 2, 297, 98, 2, 2071, 56, 2, 141, 2, 194, 2, 2, 2, 226, 2, 2, 134, 476, 2, 480, 2, 144, 2, 2, 2, 51, 2, 2, 224, 92, 2, 104, 2, 226, 65, 2, 2, 1334, 88, 2, 2, 283, 2, 2, 4472, 113, 103, 2, 2, 2, 2, 2, 178, 2]),\n",
       "       list([2, 194, 1153, 194, 2, 78, 228, 2, 2, 1463, 4369, 2, 134, 2, 2, 715, 2, 118, 1634, 2, 394, 2, 2, 119, 954, 189, 102, 2, 207, 110, 3103, 2, 2, 69, 188, 2, 2, 2, 2, 2, 249, 126, 93, 2, 114, 2, 2300, 1523, 2, 647, 2, 116, 2, 2, 2, 2, 229, 2, 340, 1322, 2, 118, 2, 2, 130, 4901, 2, 2, 1002, 2, 89, 2, 952, 2, 2, 2, 455, 2, 2, 2, 2, 1543, 1905, 398, 2, 1649, 2, 2, 2, 163, 2, 3215, 2, 2, 1153, 2, 194, 775, 2, 2, 2, 349, 2637, 148, 605, 2, 2, 2, 123, 125, 68, 2, 2, 2, 349, 165, 4362, 98, 2, 2, 228, 2, 2, 2, 1157, 2, 299, 120, 2, 120, 174, 2, 220, 175, 136, 50, 2, 4373, 228, 2, 2, 2, 656, 245, 2350, 2, 2, 2, 131, 152, 491, 2, 2, 2, 2, 1212, 2, 2, 2, 371, 78, 2, 625, 64, 1382, 2, 2, 168, 145, 2, 2, 1690, 2, 2, 2, 1355, 2, 2, 2, 52, 154, 462, 2, 89, 78, 285, 2, 145, 95])], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2] \n",
    "#Reserved:  0 reserved for padding; 1 would be starting character; 2 is unknown; 3 is most common word, 4 second most commun, ..... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "189\n",
      "141\n",
      "550\n",
      "147\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "#checking the lenth\n",
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the classification of the first 6 reviews\n",
    "y_train[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 25000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the sizes of training and validation sets\n",
    "len(x_train), len(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restoring words from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1589248/1641221 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "# starting from 3; the rest were reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"PAD\"] = 0\n",
    "word_index[\"START\"] = 1\n",
    "word_index[\"UNK\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'suwa': 31248,\n",
       " \"wrap'ed\": 71215,\n",
       " 'artisan': 29104,\n",
       " 'starkest': 52800,\n",
       " \"'homosexual\": 54816,\n",
       " \"manufacturer's\": 53543,\n",
       " 'authoring': 60149,\n",
       " 'handpicked': 51371,\n",
       " 'dodekakuple': 83968,\n",
       " 'emission': 66133,\n",
       " 'apprehensions': 69443,\n",
       " \"ballad'\": 88045,\n",
       " 'spidey': 25022,\n",
       " \"mortimer's\": 37417,\n",
       " 'strangelove': 11465,\n",
       " \"cruel'\": 77276,\n",
       " 'unfaithal': 72754,\n",
       " 'it\\x97can': 65985,\n",
       " 'unlovable': 28100,\n",
       " \"napier's\": 46105,\n",
       " '395': 70502,\n",
       " 'ourt': 86515,\n",
       " 'noth': 32171,\n",
       " \"'everyone\": 62745,\n",
       " 'vili': 49987,\n",
       " 'composing': 21354,\n",
       " 'sandstorm': 33531,\n",
       " 'im': 4604,\n",
       " 'chronologies': 52954,\n",
       " 'yuggoslavia': 58600,\n",
       " 'havnt': 41950,\n",
       " 'protegé': 64179,\n",
       " 'neul': 40633,\n",
       " 'duplicates': 44412,\n",
       " 'artemesia': 36290,\n",
       " 'jbl': 30921,\n",
       " 'pseudoscience': 29748,\n",
       " '‘lifer’': 75728,\n",
       " 'quits': 18402,\n",
       " 'cereal': 21970,\n",
       " 'narcoleptic': 43100,\n",
       " 'enquanto': 62703,\n",
       " \"referee's\": 83592,\n",
       " 'unavoidably': 27408,\n",
       " 'flurry': 23329,\n",
       " 'tightening': 21201,\n",
       " '\\x84richard': 62239,\n",
       " '09': 22373,\n",
       " 'obese': 14364,\n",
       " 'derby': 41104,\n",
       " 'looniness': 77875,\n",
       " 'gnashing': 41765,\n",
       " 'macadams': 81421,\n",
       " '109': 28564,\n",
       " 'bacchus': 87775,\n",
       " 'smiles': 5852,\n",
       " 'earnestness': 23374,\n",
       " 'apart': 972,\n",
       " \"weir's\": 21687,\n",
       " 'relaxing': 9073,\n",
       " 'contre': 61549,\n",
       " \"lensky's\": 53225,\n",
       " 'occurrences': 12188,\n",
       " 'pffffft': 61095,\n",
       " 'berlin': 4456,\n",
       " \"matrix'\": 23379,\n",
       " 'ladylove': 60936,\n",
       " 'finns': 41899,\n",
       " 'kerb': 80605,\n",
       " 'goro': 40512,\n",
       " 'clue': 2307,\n",
       " 'several': 450,\n",
       " \"kazan's\": 16913,\n",
       " 'pinjar': 13724,\n",
       " 'font': 30347,\n",
       " 'physcological': 54738,\n",
       " \"noë's\": 70187,\n",
       " 'kathmandu': 23701,\n",
       " \"enya's\": 79707,\n",
       " 'exelence': 79461,\n",
       " 'inordinately': 29688,\n",
       " 'stale': 4801,\n",
       " 'kebbel': 83841,\n",
       " 'donnas': 75730,\n",
       " 'chistina': 84921,\n",
       " \"schnaas's\": 86507,\n",
       " 'wowzers': 48610,\n",
       " 'uta': 83567,\n",
       " 'deaky': 86060,\n",
       " 'daisuke': 35298,\n",
       " 'heartfelt': 5348,\n",
       " 'interminably': 37303,\n",
       " 'tewksbury': 37301,\n",
       " 'abilityof': 63040,\n",
       " 'hoisted': 44219,\n",
       " 'think': 104,\n",
       " 'branching': 44459,\n",
       " \"'gypsy\": 50622,\n",
       " 'subsp': 68819,\n",
       " 'town\\x85': 84726,\n",
       " 'mehki': 48722,\n",
       " 'goodie': 22201,\n",
       " 'nicktoons': 44793,\n",
       " 'sinha': 69249,\n",
       " 'prequels': 17216,\n",
       " \"blackhawk's\": 56205,\n",
       " 'holey': 61738,\n",
       " 'tugged': 26824,\n",
       " 'londonesque': 73351,\n",
       " 'howell': 24415,\n",
       " 'takers': 50161,\n",
       " 'implement': 27865,\n",
       " 'pox': 36882,\n",
       " 'walthal': 58201,\n",
       " 'counseler': 85003,\n",
       " 'refocused': 68433,\n",
       " 'jokiness': 66405,\n",
       " 'secs': 33450,\n",
       " 'coppers': 28186,\n",
       " '¡§october': 64389,\n",
       " 'visualizing': 40775,\n",
       " 'enyoyed': 59906,\n",
       " \"ford's\": 6489,\n",
       " 'zardoz': 50317,\n",
       " 'fishburn': 35553,\n",
       " 'intergroup': 80353,\n",
       " 'abounding': 55584,\n",
       " 'shunted': 39483,\n",
       " \"'paris\": 22293,\n",
       " 'trailers': 4241,\n",
       " 'berrisford': 60134,\n",
       " 'whishaw': 36916,\n",
       " 'isild': 56108,\n",
       " \"'south\": 41000,\n",
       " 'swanston': 47667,\n",
       " 'abortionist': 81966,\n",
       " 'misunderstandings': 11780,\n",
       " 'optimists': 75764,\n",
       " 'rachael': 17036,\n",
       " 'kafkanian': 78237,\n",
       " 'atm': 50550,\n",
       " 'saxony': 80453,\n",
       " 'ceausescu': 33897,\n",
       " \"marley's\": 38394,\n",
       " 'itelf': 87301,\n",
       " \"industry'\": 85271,\n",
       " 'defensiveness': 83148,\n",
       " 'daaaarrrkk': 58685,\n",
       " 'selfish\\x85': 74521,\n",
       " 'bach': 6684,\n",
       " 'viscous': 37096,\n",
       " 'tricksters': 51674,\n",
       " 'sprinkle': 37868,\n",
       " 'kenyon': 24783,\n",
       " 'mon': 16088,\n",
       " 'kelippoth': 41772,\n",
       " 'songs': 690,\n",
       " 'aniversy': 47810,\n",
       " 'lessened': 23095,\n",
       " 'adler': 33960,\n",
       " 'misconstrue': 57264,\n",
       " 'gena': 8120,\n",
       " 'marbles\\x85': 70166,\n",
       " 'salesmen': 32928,\n",
       " 'mummies': 25485,\n",
       " 'slide': 6444,\n",
       " 'angellic': 53441,\n",
       " 'synthetically': 55000,\n",
       " 'dov': 81491,\n",
       " \"smallville's\": 84438,\n",
       " 'pauly': 17257,\n",
       " 'baphomets': 75903,\n",
       " 'dismaying': 48781,\n",
       " 'barraged': 38535,\n",
       " 'flinstone': 60522,\n",
       " 'disregarded': 20550,\n",
       " 'biter': 27498,\n",
       " 'wbal': 54708,\n",
       " 'handpuppets': 73843,\n",
       " 'previn': 68235,\n",
       " 'anglaise': 74532,\n",
       " 'pooing': 56378,\n",
       " 'brightens': 27820,\n",
       " 'mappo': 54662,\n",
       " 'misspellings': 74770,\n",
       " 'grandparents': 9950,\n",
       " 'betrayed': 7873,\n",
       " 'philippines': 13326,\n",
       " 'grounding': 19574,\n",
       " 'upbringings': 79133,\n",
       " 'bonaparte': 39664,\n",
       " 'exorcised': 65724,\n",
       " 'mellowed': 56403,\n",
       " 'examined': 8932,\n",
       " 'escpecially': 87003,\n",
       " 'norsk': 37002,\n",
       " 'cocoa': 35086,\n",
       " 'clu': 34045,\n",
       " 'discontent': 24625,\n",
       " \"call's\": 69523,\n",
       " \"sentinel'\": 33681,\n",
       " \"pressburger's\": 30438,\n",
       " 'gangbusters': 43255,\n",
       " 'singletons': 58004,\n",
       " 'conservatism': 24211,\n",
       " \"colin's\": 36337,\n",
       " 'whathaveyous': 82414,\n",
       " 'seymour': 6759,\n",
       " 'glinda': 87613,\n",
       " 'describes': 4213,\n",
       " 'bailout': 41590,\n",
       " 'engagingly': 29194,\n",
       " 'shadier': 50206,\n",
       " 'oughts': 48798,\n",
       " 'ephemeralness': 79784,\n",
       " 'waterfronts': 73504,\n",
       " 'reclaimed': 41032,\n",
       " 'sickeningly': 16120,\n",
       " 'unlockables': 79594,\n",
       " 'facial': 2752,\n",
       " 'taunts': 17842,\n",
       " 'entering': 6263,\n",
       " \"myriel's\": 62203,\n",
       " \"szifrón's\": 54346,\n",
       " \"beckham's\": 37886,\n",
       " \"vcr's\": 72526,\n",
       " 'kickers': 63088,\n",
       " 'glowed': 86033,\n",
       " 'mangled': 17475,\n",
       " 'enlivenes': 55807,\n",
       " 'detached': 8144,\n",
       " 'tonally': 43352,\n",
       " 'learns': 2271,\n",
       " 'fund': 11986,\n",
       " 'transmogrifies': 83763,\n",
       " 'moed': 70257,\n",
       " 'ala': 7818,\n",
       " 'acetylene': 78124,\n",
       " 'frown': 26845,\n",
       " 'kathy': 6909,\n",
       " 'mustaches': 46331,\n",
       " 'infallibility': 42934,\n",
       " 'forsaken': 13071,\n",
       " 'nivola': 81556,\n",
       " \"'movie'\": 14222,\n",
       " \"eva's\": 20762,\n",
       " 'communicate': 5702,\n",
       " 'beginning': 454,\n",
       " 'nightclubs': 22535,\n",
       " 'natasha': 8627,\n",
       " 'click': 7198,\n",
       " 'dower': 37172,\n",
       " 'imbred': 46299,\n",
       " 'sheeta': 10460,\n",
       " \"an't\": 80902,\n",
       " 'damiano': 53521,\n",
       " 'balthasar': 64621,\n",
       " \"'loulou's\": 69023,\n",
       " 'detained': 20575,\n",
       " 'horroresque': 57822,\n",
       " \"jonathan's\": 47688,\n",
       " \"'plot\": 65038,\n",
       " 'burn': 3524,\n",
       " \"'okay'\": 51852,\n",
       " 'suge': 85941,\n",
       " 'pastimes': 39358,\n",
       " 'balan': 26056,\n",
       " 'roeg': 13500,\n",
       " 'clure': 72685,\n",
       " \"sajani's\": 36408,\n",
       " 'dietrichesque': 65324,\n",
       " \"wonderland'\": 32302,\n",
       " 'incomprehensibility': 23261,\n",
       " 'trolley': 24688,\n",
       " 'gday': 59222,\n",
       " 'willow': 20384,\n",
       " 'epilepsy': 33145,\n",
       " 'commited': 69106,\n",
       " 'ravensback': 74290,\n",
       " 'yecch': 60279,\n",
       " \"'exploitation'\": 86675,\n",
       " \"carnby's\": 65850,\n",
       " 'dismissed': 12614,\n",
       " 'cockfight': 49652,\n",
       " 'moonwalking': 62066,\n",
       " 'redemeption': 71481,\n",
       " 'brewery': 36712,\n",
       " 'godfather': 3518,\n",
       " \"zimmermann's\": 80883,\n",
       " \"dalmar's\": 66445,\n",
       " '450': 85020,\n",
       " \"'initiation\": 62657,\n",
       " 'uni': 21646,\n",
       " 'mistrusting': 47388,\n",
       " \"'women\": 53337,\n",
       " 'gareth': 48854,\n",
       " 'must': 215,\n",
       " 'jewels': 11937,\n",
       " 'testifies': 30349,\n",
       " \"'disappear'\": 82496,\n",
       " 'djin': 69263,\n",
       " 'abut': 33931,\n",
       " \"crewmate's\": 71271,\n",
       " 'mid': 1696,\n",
       " 'sro': 62553,\n",
       " 'quiver': 42488,\n",
       " 'reliable': 6027,\n",
       " \"'fitted'\": 53463,\n",
       " 'looped': 22922,\n",
       " \"nothing's\": 20409,\n",
       " 'voting': 9719,\n",
       " 'bachmann': 65385,\n",
       " 'premiered': 8433,\n",
       " 'trimming': 26602,\n",
       " 'parke': 64195,\n",
       " \"gangsters'\": 44332,\n",
       " 'interacts': 22053,\n",
       " 'teodoro': 36145,\n",
       " 'dunk': 15000,\n",
       " 'mospeada': 44736,\n",
       " 'cello': 32381,\n",
       " 'conceal': 12972,\n",
       " 'breakers': 21385,\n",
       " 'conquer': 10576,\n",
       " 'charli': 64161,\n",
       " 'whaddayagonndo': 81075,\n",
       " 'tenderly': 28641,\n",
       " \"james'\": 21078,\n",
       " 'soloist': 33689,\n",
       " 'indolently': 58334,\n",
       " 'lodging': 33604,\n",
       " 'numerous': 1942,\n",
       " 'renoir': 11604,\n",
       " 'shakespearian': 17361,\n",
       " \"darin's\": 56693,\n",
       " 'outside': 1005,\n",
       " 'daftness': 49116,\n",
       " 'startling': 6078,\n",
       " 'husband': 658,\n",
       " 'cyndy': 51405,\n",
       " 'gogol': 55550,\n",
       " 'barley': 27869,\n",
       " \"soup's\": 38090,\n",
       " 'reevaluated': 86513,\n",
       " \"boothe's\": 86722,\n",
       " \"mrs'\": 54928,\n",
       " 'descendants': 16708,\n",
       " 'rowell': 37245,\n",
       " \"briers'\": 84188,\n",
       " 'crassness': 56236,\n",
       " 'shoufukutei': 67585,\n",
       " 'frain': 39399,\n",
       " \"'anastasia\": 57121,\n",
       " 'follows': 1160,\n",
       " 'kavalier': 72241,\n",
       " 'romanced': 34125,\n",
       " 'rattlesnakes': 47970,\n",
       " 'crucifixion': 21141,\n",
       " 'damningly': 71161,\n",
       " 'ashenden': 46033,\n",
       " 'devon': 13955,\n",
       " 'evacuee': 27570,\n",
       " 'deceived': 17122,\n",
       " 'thtdb': 82637,\n",
       " 'furtado': 78234,\n",
       " 'fuzzy': 7072,\n",
       " 'stalinism': 41120,\n",
       " \"paalgard's\": 59420,\n",
       " 'bureaucrat': 18537,\n",
       " 'dwelves': 57946,\n",
       " 'unbelievability': 34022,\n",
       " 'syrianna': 80319,\n",
       " 'youngest\\x97and': 72594,\n",
       " 'superdome': 22937,\n",
       " 'lame': 835,\n",
       " 'mujar': 58507,\n",
       " \"thinnes'\": 78010,\n",
       " 'descend': 19491,\n",
       " 'kossak': 42869,\n",
       " 'krazy': 55832,\n",
       " 'agonizes': 46746,\n",
       " 'embarking': 29970,\n",
       " \"cimino's\": 34986,\n",
       " 'overstuffed': 35412,\n",
       " \"jouvet's\": 70099,\n",
       " 'eumaeus': 61096,\n",
       " 'sharpville': 62977,\n",
       " 'gabel': 26728,\n",
       " 'weaker': 6118,\n",
       " 'ginelli': 77511,\n",
       " '1\\x85': 80526,\n",
       " 'saluting': 58643,\n",
       " 'foxed': 56447,\n",
       " 'forgery': 51192,\n",
       " 'seediest': 46765,\n",
       " 'vaule': 86925,\n",
       " \"here\\x97it's\": 84395,\n",
       " 'bouffant': 60072,\n",
       " 'recognition': 4637,\n",
       " 'barsaat': 58459,\n",
       " 'togar': 12310,\n",
       " 'davonne': 62661,\n",
       " 'parlors': 33337,\n",
       " 'tempest': 11714,\n",
       " 'pres': 24481,\n",
       " 'rosco': 23732,\n",
       " 'sagemiller': 18844,\n",
       " 'resets': 77790,\n",
       " 'jax': 46732,\n",
       " 'humoured': 33984,\n",
       " 'fluctuating': 51128,\n",
       " 'hanzo': 8771,\n",
       " \"ackroyd's\": 69036,\n",
       " \"kumar's\": 26241,\n",
       " 'underflowing': 50746,\n",
       " 'earnest': 6359,\n",
       " 'hauled': 17564,\n",
       " 'pliant': 61399,\n",
       " \"labour's\": 23251,\n",
       " 'ruffians': 44926,\n",
       " \"youth's\": 41861,\n",
       " 'adj': 82481,\n",
       " 'rakastin': 55921,\n",
       " 'hypnotizing': 37000,\n",
       " 'pantheon': 13798,\n",
       " 'barred': 14628,\n",
       " 'polarised': 56018,\n",
       " 'steckler': 44337,\n",
       " 'pannings': 85178,\n",
       " 'klara': 23362,\n",
       " 'vipul': 11374,\n",
       " \"elmes's\": 76073,\n",
       " \"lovers'\": 26238,\n",
       " 'aleister': 45059,\n",
       " \"'butthorn'\": 54132,\n",
       " 'fops': 63620,\n",
       " \"d'art\": 49088,\n",
       " 'caratherisic': 88170,\n",
       " 'impersonations': 24429,\n",
       " \"'premature\": 57861,\n",
       " 'waterworks': 42494,\n",
       " 'baichwal': 43372,\n",
       " 'shylock': 59278,\n",
       " 'milkman': 47503,\n",
       " 'algerians': 61314,\n",
       " 'disciplined': 24436,\n",
       " 'nordic': 22732,\n",
       " 'eick': 43611,\n",
       " \"hospital's\": 37657,\n",
       " 'philadelphia': 9442,\n",
       " 'gustafson': 77624,\n",
       " 'assuring': 34841,\n",
       " 'dumbs': 29215,\n",
       " 'wannabes': 14777,\n",
       " 'plante': 65132,\n",
       " \"mcintire's\": 45000,\n",
       " 'ranch\\x85': 59323,\n",
       " 'squalor': 13447,\n",
       " 'battling': 8165,\n",
       " 'mow': 30407,\n",
       " \"babbage's\": 34531,\n",
       " 'dragons': 6407,\n",
       " \"'americana'\": 81473,\n",
       " 'goods': 6610,\n",
       " 'jaded': 6650,\n",
       " 'boomerang': 21831,\n",
       " 'forced': 918,\n",
       " 'racked': 24433,\n",
       " 'posterior': 30317,\n",
       " \"1932's\": 37906,\n",
       " 'coworker': 21682,\n",
       " 'chitchatting': 62991,\n",
       " 'symbiotes': 71772,\n",
       " 'actriss': 55037,\n",
       " \"'point\": 82996,\n",
       " 'notre': 17750,\n",
       " 'condemns': 29325,\n",
       " \"ran's\": 79335,\n",
       " \"judas'\": 74551,\n",
       " 'intensive': 16791,\n",
       " 'amasses': 86704,\n",
       " 'breathy': 86104,\n",
       " \"i'd\": 474,\n",
       " 'overstate': 41344,\n",
       " 'commodore': 23474,\n",
       " 'ought': 3882,\n",
       " \"'hoovervilles'\": 74228,\n",
       " 'envelop': 39660,\n",
       " 'sabina': 22083,\n",
       " \"sloane's\": 44713,\n",
       " 'audiard': 13452,\n",
       " 'chimpanzee': 27513,\n",
       " 'itchy': 9761,\n",
       " 'subtract': 24134,\n",
       " 'ploughs': 84413,\n",
       " \"kinng'\": 83361,\n",
       " 'insufficiently': 23403,\n",
       " 'genxyz': 58741,\n",
       " 'amuro': 62424,\n",
       " 'grounded': 9355,\n",
       " 'constained': 63029,\n",
       " 'insert': 7593,\n",
       " \"engrossed'\": 67374,\n",
       " 'clemence': 55988,\n",
       " 'interconnectivity': 47211,\n",
       " 'alvira': 69009,\n",
       " 'iago': 12669,\n",
       " \"'dumb\": 42842,\n",
       " 'brontëan': 77264,\n",
       " \"pros's\": 75196,\n",
       " 'feeding': 5795,\n",
       " 'macbook': 83900,\n",
       " 'feinting': 73741,\n",
       " 'adrian': 6741,\n",
       " 'dat': 30452,\n",
       " 'clamps': 30973,\n",
       " 'mainframes': 75265,\n",
       " 'frauded': 65468,\n",
       " 'welliver': 80484,\n",
       " 'exercising': 39598,\n",
       " \"pilgrimage's\": 76837,\n",
       " 'lezlie': 31965,\n",
       " \"méliès'\": 52522,\n",
       " 'archaeologically': 81535,\n",
       " 'prolongs': 44415,\n",
       " 'sébastien': 45845,\n",
       " 'contemplating': 10858,\n",
       " 'melyvn': 85382,\n",
       " 'electricity': 9014,\n",
       " 'cycling': 23264,\n",
       " 'dungy': 73395,\n",
       " 'só': 57611,\n",
       " 'validate': 31778,\n",
       " 'spread': 4600,\n",
       " 'stitching': 36973,\n",
       " 'spartacus': 24350,\n",
       " 'sinus': 27719,\n",
       " 'stepehn': 54745,\n",
       " 'doxen': 58847,\n",
       " \"poirot's\": 36959,\n",
       " 'float': 10216,\n",
       " 'tedra': 54144,\n",
       " 'comprehensibility': 70229,\n",
       " 'drifting': 13963,\n",
       " 'clunkily': 47727,\n",
       " 'launches': 20972,\n",
       " 'jackhammer': 43705,\n",
       " \"tristesse'\": 41962,\n",
       " \"sam'\": 42975,\n",
       " 'ragman': 47685,\n",
       " \"sutcliffe's\": 82658,\n",
       " 'carfare': 69986,\n",
       " 'kino': 20742,\n",
       " 'erases': 24373,\n",
       " 'camping': 7793,\n",
       " 'xvii': 55248,\n",
       " 'sciorra': 46481,\n",
       " 'crusoe': 35303,\n",
       " 'lafont': 30808,\n",
       " 'beluschi': 79451,\n",
       " 'infatuation': 16196,\n",
       " 'mckellen': 31616,\n",
       " 'intermediate': 55078,\n",
       " 'dott': 61043,\n",
       " 'vexatious': 76672,\n",
       " 'mundial': 71552,\n",
       " 'unabridged': 41396,\n",
       " \"danube'\": 84308,\n",
       " 'adreno': 81458,\n",
       " 'juan': 7118,\n",
       " 'obscure': 3720,\n",
       " 'wouldhave': 75699,\n",
       " 'leonardo': 11757,\n",
       " 'macaw': 38846,\n",
       " 'ba': 19136,\n",
       " 'solange': 58449,\n",
       " 'aniston': 8704,\n",
       " 'vânätoarea': 66054,\n",
       " 'sleepovers': 79942,\n",
       " \"ja'net\": 56559,\n",
       " 'characteriology': 74276,\n",
       " 'decorator': 75164,\n",
       " 'gymnastics': 19539,\n",
       " 'aspect': 1251,\n",
       " 'deverell': 83495,\n",
       " 'dillon': 8949,\n",
       " 'rapid': 7050,\n",
       " \"scissorhands'\": 85925,\n",
       " 'whack': 12163,\n",
       " 'just\\x85well': 79588,\n",
       " 'navy': 3029,\n",
       " 'bruise': 29409,\n",
       " 'scrapping': 42303,\n",
       " 'stereotype': 4375,\n",
       " 'sílvia': 56337,\n",
       " 'une': 20406,\n",
       " 'conquistadors': 31337,\n",
       " \"tomb'\": 73335,\n",
       " 'winstone': 29370,\n",
       " 'scalese': 44771,\n",
       " 'pin': 5012,\n",
       " 'aq': 42295,\n",
       " 'mortality': 15007,\n",
       " 'ballroom': 8642,\n",
       " 'wedlock': 26556,\n",
       " 'rima': 41878,\n",
       " 'exposes': 9889,\n",
       " 'charlsten': 58420,\n",
       " 'gotcha': 33755,\n",
       " 'tah': 87118,\n",
       " 'ctm': 66409,\n",
       " 'originator': 83523,\n",
       " 'kdos': 80081,\n",
       " 'hurting': 9657,\n",
       " 'ruin': 2457,\n",
       " 'mulher': 57761,\n",
       " 'ornithochirus': 71655,\n",
       " \"kareena's\": 65631,\n",
       " 'vulgate': 65012,\n",
       " 'crocket': 77801,\n",
       " 'criminology': 80439,\n",
       " 'tacones': 38513,\n",
       " 'hindersome': 75820,\n",
       " 'lonette': 25475,\n",
       " 'electrifying': 12727,\n",
       " \"tone's\": 34591,\n",
       " 'buzzwords': 55688,\n",
       " \"godzilla's\": 46799,\n",
       " 'adventure': 1154,\n",
       " 'armaggeddon': 60097,\n",
       " 'corrugated': 83209,\n",
       " 'clevage': 88426,\n",
       " 'dateline': 69299,\n",
       " 'dominoes': 31084,\n",
       " \"'swimming\": 83046,\n",
       " 'kagan': 28627,\n",
       " \"eastwood's\": 9137,\n",
       " \"stratten's\": 36204,\n",
       " 'hrithek': 65914,\n",
       " 'noli': 76131,\n",
       " \"darkwolf's\": 59607,\n",
       " 'dixton': 81418,\n",
       " 'evolutionists': 71527,\n",
       " \"jersey's\": 67922,\n",
       " 'blackouts': 32492,\n",
       " 'cylinders': 30681,\n",
       " 'anaglyph': 75539,\n",
       " 'nichole': 19426,\n",
       " 'negahban': 75781,\n",
       " \"'facilitated\": 60752,\n",
       " 'haldane': 38458,\n",
       " 'habilities': 67568,\n",
       " 'definatey': 76769,\n",
       " 'beauseigneur': 85440,\n",
       " 'scattergun': 67558,\n",
       " 'weidemann': 74965,\n",
       " 'peww': 83649,\n",
       " 'unmindful': 49160,\n",
       " 'shouting': 5763,\n",
       " 'sandell': 44586,\n",
       " 'toten': 71213,\n",
       " 'prowess': 12002,\n",
       " 'principe': 67975,\n",
       " 'flds': 35038,\n",
       " 'pharaohs': 63647,\n",
       " 'confidant': 18589,\n",
       " 'stroesser': 57790,\n",
       " \"serve'\": 86955,\n",
       " 'cheekboned': 52659,\n",
       " 'coinciding': 65830,\n",
       " 'thirsty\\x85': 60139,\n",
       " 'shivers': 15589,\n",
       " 'macintoshs': 71588,\n",
       " 'brimming': 17294,\n",
       " 'brujas': 58960,\n",
       " 'cherche': 59039,\n",
       " 'envoy': 40240,\n",
       " 'spirit\\x85': 71662,\n",
       " 'preferred': 5947,\n",
       " 'nuremburg': 33069,\n",
       " 'gripping': 3133,\n",
       " 'ariauna': 28451,\n",
       " 'isint': 84334,\n",
       " 'afirming': 78240,\n",
       " 'freezer': 20977,\n",
       " 'numspa': 36129,\n",
       " 'frenchman': 9943,\n",
       " 'expansive': 16523,\n",
       " 'ladys': 69475,\n",
       " 'magrath': 48637,\n",
       " 'sociopathic': 22962,\n",
       " \"'laura\": 67643,\n",
       " 'rocaille': 63332,\n",
       " 'yamika': 84796,\n",
       " 'statesmanship': 74737,\n",
       " \"jansen's\": 39672,\n",
       " 'kempo': 80918,\n",
       " 'living': 581,\n",
       " 'hanna': 12153,\n",
       " 'ulu': 68290,\n",
       " 'morven': 81660,\n",
       " 'condos': 35598,\n",
       " '1964': 8751,\n",
       " 'iii': 3448,\n",
       " \"'slut'\": 70017,\n",
       " 'distinctions': 30519,\n",
       " \"'craig'\": 52306,\n",
       " 'freckle': 47297,\n",
       " \"horler's\": 65193,\n",
       " 'suiters': 73231,\n",
       " 'freleng': 35944,\n",
       " 'hempstead': 76937,\n",
       " 'billie': 10246,\n",
       " 'divisions': 28642,\n",
       " 'womaniser': 34514,\n",
       " 'anglos': 29450,\n",
       " 'queen': 1652,\n",
       " 'confessionals': 69955,\n",
       " 'elways': 79664,\n",
       " 'absorbed': 5742,\n",
       " 'migraines': 30297,\n",
       " 'harald': 40109,\n",
       " 'skulking': 36487,\n",
       " 'desegregation': 70969,\n",
       " 'nicolosi': 63588,\n",
       " 'cosmetically': 83532,\n",
       " 'neurotically': 45655,\n",
       " 'distastefully': 82906,\n",
       " \"'stargate\": 48653,\n",
       " 'boldness': 22512,\n",
       " 'gutters': 88470,\n",
       " 'sundae': 42930,\n",
       " \"mellisa's\": 53644,\n",
       " \"amazing's\": 75846,\n",
       " \"'hype'\": 69177,\n",
       " 'knighthood': 36695,\n",
       " 'deel': 63772,\n",
       " 'dateless': 50742,\n",
       " 'eclectic': 14575,\n",
       " 'bathouse': 60395,\n",
       " 'television': 699,\n",
       " 'bendingly': 78990,\n",
       " 'travestite': 79103,\n",
       " \"'cuban'\": 79628,\n",
       " 'britishness': 36923,\n",
       " 'positioning': 35587,\n",
       " 'progressive\\x97commandant': 77203,\n",
       " 'pinhead': 32481,\n",
       " \"'project\": 62544,\n",
       " 'givney': 61962,\n",
       " 'shambles': 11023,\n",
       " 'pressures': 10370,\n",
       " 'stumbling': 9129,\n",
       " 'kolton': 66903,\n",
       " 'deille': 65173,\n",
       " 'televised': 12453,\n",
       " 'tribal': 12024,\n",
       " 'sang': 6796,\n",
       " 'bukhanovsky': 39900,\n",
       " \"voters'\": 75267,\n",
       " 'typing\\x85': 63906,\n",
       " 'ferrer': 12330,\n",
       " 'omid': 43030,\n",
       " 'hurriedly': 19631,\n",
       " 'pundits': 66039,\n",
       " 'sympathizing': 33103,\n",
       " 'coastal': 12604,\n",
       " 'predisposed': 31921,\n",
       " 'correlation': 27187,\n",
       " 'mifune': 26438,\n",
       " 'smushed': 68582,\n",
       " 'omission': 20004,\n",
       " 'salvo': 52761,\n",
       " 'violinist': 28089,\n",
       " 'dominate': 8054,\n",
       " \"mork's\": 53622,\n",
       " 'schoolwork': 51143,\n",
       " 'schmid': 14776,\n",
       " 'aluminum': 21878,\n",
       " 'wed': 16504,\n",
       " 'hemo': 21227,\n",
       " 'muckerji': 38797,\n",
       " 'scouted': 36793,\n",
       " 'rev': 19808,\n",
       " '1865': 35870,\n",
       " 'saying': 660,\n",
       " 'x2': 29833,\n",
       " '5200': 79840,\n",
       " 'tenant': 5957,\n",
       " 'zapar': 78610,\n",
       " 'parsons': 6715,\n",
       " 'rietman': 66535,\n",
       " 'annex': 35575,\n",
       " 'costarring': 55984,\n",
       " 'parineeta': 41676,\n",
       " 'charlize': 16160,\n",
       " 'layabout': 28269,\n",
       " \"ro'\": 55506,\n",
       " \"shortland's\": 86393,\n",
       " 'creamed': 51210,\n",
       " 'onslow': 66128,\n",
       " 'begats': 54706,\n",
       " 'doxy': 83683,\n",
       " 'noelle': 39971,\n",
       " 'blyton': 83768,\n",
       " 'vertido': 46325,\n",
       " \"yes\\x85it's\": 79596,\n",
       " 'glickenhaus': 47653,\n",
       " 'codpieces': 63212,\n",
       " 'motorola': 53871,\n",
       " 'diamnd': 78348,\n",
       " \"a'hunting\": 52436,\n",
       " 'off\\x85': 67926,\n",
       " \"'hey\": 20979,\n",
       " 'schine': 83835,\n",
       " 'raquel': 13545,\n",
       " 'reimann': 45672,\n",
       " 'freckles': 38007,\n",
       " 'enviably': 56117,\n",
       " 'xvid': 55249,\n",
       " 'vampiros': 30656,\n",
       " 'ariell': 67939,\n",
       " 'woebegone': 40802,\n",
       " 'gummo': 30047,\n",
       " 'filmometer': 69032,\n",
       " 'journalists': 11834,\n",
       " 'sophie': 6616,\n",
       " \"cbs'\": 73303,\n",
       " 'afterlife': 11105,\n",
       " 'worringly': 76227,\n",
       " 'doubt': 824,\n",
       " 'slacked': 87149,\n",
       " \"'doctor'\": 65692,\n",
       " 'gambles': 33916,\n",
       " \"gloves'\": 75693,\n",
       " 'conning': 21998,\n",
       " 'goatees': 68479,\n",
       " \"1972's\": 37710,\n",
       " \"rossetti's\": 74990,\n",
       " 'utopian': 21862,\n",
       " 'persson': 66812,\n",
       " 'natty': 51567,\n",
       " 'sahsa': 57055,\n",
       " 'dissapointing': 73006,\n",
       " 'conquered': 17005,\n",
       " 'shaven': 30378,\n",
       " 'vasectomies': 55236,\n",
       " 'abnormality': 65147,\n",
       " 'kristensen': 60931,\n",
       " \"allen's\": 5864,\n",
       " \"ashby's\": 57029,\n",
       " 'blast': 5154,\n",
       " 'brd': 53117,\n",
       " \"\\x91order'\": 76217,\n",
       " 'puritan': 24862,\n",
       " 'violation': 18336,\n",
       " \"fiancee's\": 78773,\n",
       " 'aznable': 68990,\n",
       " 'guiltily': 56690,\n",
       " 'continuous': 9223,\n",
       " 'silvestar': 84693,\n",
       " 'unmistakably': 21787,\n",
       " 'organizer': 47798,\n",
       " 'goldcrest': 65284,\n",
       " 'interrogating': 24140,\n",
       " 'discharged': 26894,\n",
       " 'chained': 11890,\n",
       " 'showpiece': 32495,\n",
       " 'poffysmoviemania': 50608,\n",
       " 'awkrawrd': 54366,\n",
       " \"hatton's\": 31861,\n",
       " 'trampy': 61870,\n",
       " 'karlsson': 60053,\n",
       " 'royersford': 75664,\n",
       " 'popularizing': 54157,\n",
       " 'lidia': 49260,\n",
       " 'installment': 3668,\n",
       " 'avg': 43511,\n",
       " \"'baptists\": 34768,\n",
       " 'wonders': 3575,\n",
       " 'cadences': 80394,\n",
       " \"'march\": 76166,\n",
       " 'homes': 6153,\n",
       " 'drollness': 84073,\n",
       " 'pendelton': 31269,\n",
       " 'unquestionably': 12219,\n",
       " 'adhesive': 51217,\n",
       " 'measurably': 54458,\n",
       " 'eerier': 59818,\n",
       " \"throat'\": 70091,\n",
       " 'runner': 5808,\n",
       " 'sudsy': 40128,\n",
       " 'lawmen': 37260,\n",
       " 'freak': 3841,\n",
       " 'keisha': 31612,\n",
       " 'sydow': 12850,\n",
       " \"kelemen's\": 76261,\n",
       " 'delauise': 54544,\n",
       " '£500': 66353,\n",
       " \"pachabel's\": 67044,\n",
       " 'mxyzptlk': 80927,\n",
       " 'ravish': 38158,\n",
       " 'independant': 34090,\n",
       " 'bendix': 20617,\n",
       " 'zillions': 31087,\n",
       " 'ramya': 79663,\n",
       " 'kang': 20713,\n",
       " 'equity': 84514,\n",
       " 'arhtur': 54141,\n",
       " 'broz': 56742,\n",
       " \"baronland's\": 82008,\n",
       " 'lotus': 27048,\n",
       " \"'ye'\": 57676,\n",
       " 'bondless': 68436,\n",
       " 'courtyard': 16432,\n",
       " 'actress\\x85': 65100,\n",
       " 'steampile': 81973,\n",
       " 'halleck': 24820,\n",
       " 'evilly': 35039,\n",
       " \"soraj's\": 83795,\n",
       " 'inevitability': 16004,\n",
       " 'life\\x85well': 87821,\n",
       " 'iranian': 7246,\n",
       " 'donati': 51479,\n",
       " \"'eliminated'\": 60770,\n",
       " 'blonds': 41550,\n",
       " 'recurrently': 80719,\n",
       " 'harbours': 88094,\n",
       " 'dousing': 34951,\n",
       " 'sndtrk': 44882,\n",
       " 'darcey': 53597,\n",
       " 'sequencing': 33351,\n",
       " 'next\\x85': 69614,\n",
       " 'buckled': 58557,\n",
       " 'driller': 37193,\n",
       " \"fishing'\": 62108,\n",
       " 'empathic': 44204,\n",
       " \"'renassaince'\": 71782,\n",
       " 'domesticate': 38930,\n",
       " \"'nutcracker'\": 87884,\n",
       " \"'46\": 44171,\n",
       " 'inspite': 27879,\n",
       " \"future's\": 77866,\n",
       " 'robber': 11232,\n",
       " 'sylvan': 38117,\n",
       " 'streeb': 63306,\n",
       " 'rosina': 49249,\n",
       " 'chiara': 40869,\n",
       " 'michalis': 50266,\n",
       " \"pleasantville's\": 60227,\n",
       " 'titillation': 15431,\n",
       " 'wards': 13667,\n",
       " 'hawkins': 19158,\n",
       " 'faithful': 2737,\n",
       " 'tribeca': 17124,\n",
       " 'cedric': 7977,\n",
       " 'ips': 81010,\n",
       " 'volts': 52868,\n",
       " 'rånarna': 48687,\n",
       " 'ironic': 2954,\n",
       " 'hive': 40390,\n",
       " 'laps': 51564,\n",
       " \"spigott'\": 85914,\n",
       " 'tactically': 38455,\n",
       " 'semantics': 45480,\n",
       " 'treason': 16926,\n",
       " 'androgynous': 30394,\n",
       " 'victoires': 30322,\n",
       " \"dave's\": 51832,\n",
       " 'grat': 81225,\n",
       " 'anda': 55538,\n",
       " 'remedios': 48970,\n",
       " 'paps': 87046,\n",
       " 'gracelessly': 65181,\n",
       " 'sporadically': 13103,\n",
       " 'christers': 57693,\n",
       " 'union': 3617,\n",
       " 'sexton': 35492,\n",
       " 'mundance': 81405,\n",
       " 'abode': 30547,\n",
       " 'happpeniiiinngggg': 54012,\n",
       " 'guinneapig': 58795,\n",
       " 'web\\x85': 55099,\n",
       " 'headliner': 37727,\n",
       " 'won': 1199,\n",
       " 'yield': 26319,\n",
       " 'peva': 48482,\n",
       " 'teddy': 8941,\n",
       " 'excellent': 321,\n",
       " 'rayburn': 43759,\n",
       " 'libyan': 52184,\n",
       " 'traitors': 27629,\n",
       " 'joe': 914,\n",
       " 'slitter': 71374,\n",
       " 'invective': 38303,\n",
       " \"shots'\": 41988,\n",
       " \"boxer's\": 41656,\n",
       " 'erred': 85371,\n",
       " 'goodhearted': 51957,\n",
       " 'gershwyn': 74915,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversing Keys:Values\n",
    "index_word = {v:k for k,v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 973,\n",
       " 1622,\n",
       " 1385,\n",
       " 65,\n",
       " 458,\n",
       " 4468,\n",
       " 66,\n",
       " 3941,\n",
       " 2,\n",
       " 173,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 100,\n",
       " 2,\n",
       " 838,\n",
       " 112,\n",
       " 50,\n",
       " 670,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 284,\n",
       " 2,\n",
       " 150,\n",
       " 2,\n",
       " 172,\n",
       " 112,\n",
       " 167,\n",
       " 2,\n",
       " 336,\n",
       " 385,\n",
       " 2,\n",
       " 2,\n",
       " 172,\n",
       " 4536,\n",
       " 1111,\n",
       " 2,\n",
       " 546,\n",
       " 2,\n",
       " 2,\n",
       " 447,\n",
       " 2,\n",
       " 192,\n",
       " 50,\n",
       " 2,\n",
       " 2,\n",
       " 147,\n",
       " 2025,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1920,\n",
       " 4613,\n",
       " 469,\n",
       " 2,\n",
       " 2,\n",
       " 71,\n",
       " 87,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 530,\n",
       " 2,\n",
       " 76,\n",
       " 2,\n",
       " 2,\n",
       " 1247,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 515,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 626,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 62,\n",
       " 386,\n",
       " 2,\n",
       " 2,\n",
       " 316,\n",
       " 2,\n",
       " 106,\n",
       " 2,\n",
       " 2,\n",
       " 2223,\n",
       " 2,\n",
       " 2,\n",
       " 480,\n",
       " 66,\n",
       " 3785,\n",
       " 2,\n",
       " 2,\n",
       " 130,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 619,\n",
       " 2,\n",
       " 2,\n",
       " 124,\n",
       " 51,\n",
       " 2,\n",
       " 135,\n",
       " 2,\n",
       " 2,\n",
       " 1415,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 215,\n",
       " 2,\n",
       " 77,\n",
       " 52,\n",
       " 2,\n",
       " 2,\n",
       " 407,\n",
       " 2,\n",
       " 82,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 107,\n",
       " 117,\n",
       " 2,\n",
       " 2,\n",
       " 256,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3766,\n",
       " 2,\n",
       " 723,\n",
       " 2,\n",
       " 71,\n",
       " 2,\n",
       " 530,\n",
       " 476,\n",
       " 2,\n",
       " 400,\n",
       " 317,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1029,\n",
       " 2,\n",
       " 104,\n",
       " 88,\n",
       " 2,\n",
       " 381,\n",
       " 2,\n",
       " 297,\n",
       " 98,\n",
       " 2,\n",
       " 2071,\n",
       " 56,\n",
       " 2,\n",
       " 141,\n",
       " 2,\n",
       " 194,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 226,\n",
       " 2,\n",
       " 2,\n",
       " 134,\n",
       " 476,\n",
       " 2,\n",
       " 480,\n",
       " 2,\n",
       " 144,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 51,\n",
       " 2,\n",
       " 2,\n",
       " 224,\n",
       " 92,\n",
       " 2,\n",
       " 104,\n",
       " 2,\n",
       " 226,\n",
       " 65,\n",
       " 2,\n",
       " 2,\n",
       " 1334,\n",
       " 88,\n",
       " 2,\n",
       " 2,\n",
       " 283,\n",
       " 2,\n",
       " 2,\n",
       " 4472,\n",
       " 113,\n",
       " 103,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 178,\n",
       " 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"UNK UNK UNK UNK UNK brilliant casting location scenery story direction everyone's really suited UNK part UNK played UNK UNK could UNK imagine being there robert UNK UNK UNK amazing actor UNK now UNK same being director UNK father came UNK UNK same scottish island UNK myself UNK UNK loved UNK fact there UNK UNK real connection UNK UNK UNK UNK witty remarks throughout UNK UNK were great UNK UNK UNK brilliant UNK much UNK UNK bought UNK UNK UNK soon UNK UNK UNK released UNK UNK UNK would recommend UNK UNK everyone UNK watch UNK UNK fly UNK UNK amazing really cried UNK UNK end UNK UNK UNK sad UNK UNK know what UNK say UNK UNK cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Join to see the Words, our choice was to remove the words other than the most 5000 commun ones, Therefor: lots of UNKown tokens\n",
    "' '.join(index_word[id] for id in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see all the words , without using any specefique parameters\n",
    "(all_x_train,_),(all_x_valid,_) = imdb.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisit the parameters defined above, same preprocessing for training and validation\n",
    "x_train = pad_sequences(x_train, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)\n",
    "x_valid = pad_sequences(x_valid, maxlen=max_review_length, padding=pad_type, truncating=trunc_type, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1415,    2,    2,    2,    2,  215,    2,   77,   52,    2,    2,\n",
       "         407,    2,   82,    2,    2,    2,  107,  117,    2,    2,  256,\n",
       "           2,    2,    2, 3766,    2,  723,    2,   71,    2,  530,  476,\n",
       "           2,  400,  317,    2,    2,    2,    2, 1029,    2,  104,   88,\n",
       "           2,  381,    2,  297,   98,    2, 2071,   56,    2,  141,    2,\n",
       "         194,    2,    2,    2,  226,    2,    2,  134,  476,    2,  480,\n",
       "           2,  144,    2,    2,    2,   51,    2,    2,  224,   92,    2,\n",
       "         104,    2,  226,   65,    2,    2, 1334,   88,    2,    2,  283,\n",
       "           2,    2, 4472,  113,  103,    2,    2,    2,    2,    2,  178,\n",
       "           2],\n",
       "       [ 163,    2, 3215,    2,    2, 1153,    2,  194,  775,    2,    2,\n",
       "           2,  349, 2637,  148,  605,    2,    2,    2,  123,  125,   68,\n",
       "           2,    2,    2,  349,  165, 4362,   98,    2,    2,  228,    2,\n",
       "           2,    2, 1157,    2,  299,  120,    2,  120,  174,    2,  220,\n",
       "         175,  136,   50,    2, 4373,  228,    2,    2,    2,  656,  245,\n",
       "        2350,    2,    2,    2,  131,  152,  491,    2,    2,    2,    2,\n",
       "        1212,    2,    2,    2,  371,   78,    2,  625,   64, 1382,    2,\n",
       "           2,  168,  145,    2,    2, 1690,    2,    2,    2, 1355,    2,\n",
       "           2,    2,   52,  154,  462,    2,   89,   78,  285,    2,  145,\n",
       "          95]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# all 100 legth: Shorters are padded, Longuer are truncated\n",
    "for x in x_train[0:6]:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cry UNK UNK UNK UNK must UNK been good UNK UNK definitely UNK also UNK UNK UNK two little UNK UNK played UNK UNK UNK norman UNK paul UNK were UNK brilliant children UNK often left UNK UNK UNK UNK list UNK think because UNK stars UNK play them UNK grown up UNK such UNK big UNK UNK UNK whole UNK UNK these children UNK amazing UNK should UNK UNK UNK what UNK UNK done don't UNK think UNK whole story UNK UNK lovely because UNK UNK true UNK UNK someone's life after UNK UNK UNK UNK UNK us UNK\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD PAD UNK begins better than UNK ends funny UNK UNK russian UNK crew UNK UNK other actors UNK UNK those scenes where documentary shots UNK UNK spoiler part UNK message UNK UNK contrary UNK UNK whole story UNK UNK does UNK UNK UNK UNK'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# you can try the option of pre-traning the embedding outside the NN\n",
    "model.add(Embedding(n_unique_words, n_dim, input_length=max_review_length))\n",
    "# Reducing the Dim\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "# model.add(Dense(n_dense, activation='relu'))\n",
    "# model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid')) # mathematically equivalent to softmax with two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 64)           320000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 729,729\n",
      "Trainable params: 729,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() # so many parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 5000, 320000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding layer dimensions and parameters: \n",
    "n_dim, n_unique_words, n_dim*n_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 64, 6400)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...flatten:\n",
    "max_review_length, n_dim, n_dim*max_review_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 409664)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...dense:\n",
    "n_dense, n_dim*max_review_length*n_dense + n_dense # weights + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...and output:\n",
    "n_dense + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 classes: binary crossentropy; adam=2nd order GD, metric= acuracy(0.5 threshhold)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcheckpoint = ModelCheckpoint(filepath=output_dir+\"/weights.{epoch:02d}.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat the Diroctory\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/4\n",
      "25000/25000 [==============================] - 19s - loss: 0.5386 - acc: 0.7052 - val_loss: 0.3668 - val_acc: 0.8362.705\n",
      "Epoch 2/4\n",
      "25000/25000 [==============================] - 16s - loss: 0.2731 - acc: 0.8929 - val_loss: 0.3498 - val_acc: 0.8468\n",
      "Epoch 3/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.1110 - acc: 0.9670 - val_loss: 0.4363 - val_acc: 0.8306\n",
      "Epoch 4/4\n",
      "25000/25000 [==============================] - 15s - loss: 0.0241 - acc: 0.9960 - val_loss: 0.5322 - val_acc: 0.8343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x42f295c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 84.7% validation accuracy in epoch 2\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_valid, y_valid), callbacks=[modelcheckpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to callback we can choose the wieght from the best epoch\n",
    "model.load_weights(output_dir+\"/weights.01.hdf5\") # zero-indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24960/25000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predidction on the validation \n",
    "y_hat = model.predict_proba(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.89354676], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.89 confidence that the first review is positive: IT WAS\n",
    "y_hat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x346b05c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_hat)\n",
    "_ = plt.axvline(x=0.5, color='orange')\n",
    " # for most of the reviews there is clear boundary (positive/negative), with a simplistic defintion of the metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the AUC_ROC%\n",
    "pct_auc = roc_auc_score(y_valid, y_hat)*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'92.71'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:0.2f}\".format(pct_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparatif of individual results\n",
    "# tranforming from nested lists to single list\n",
    "float_y_hat = []\n",
    "for y in y_hat:\n",
    "    float_y_hat.append(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydf = pd.DataFrame(list(zip(float_y_hat, y_valid)), columns=['y_hat', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.102744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.903662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.520158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.064371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.965295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.522287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_hat  y\n",
       "0  0.893547  1\n",
       "1  0.102744  1\n",
       "2  0.847956  1\n",
       "3  0.903662  1\n",
       "4  0.232289  1\n",
       "5  0.520158  0\n",
       "6  0.030079  0\n",
       "7  0.064371  0\n",
       "8  0.965295  1\n",
       "9  0.522287  1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'START how his charter evolved as both man and ape was outstanding not to mention the scenery of the film christopher lambert was astonishing as lord of greystoke christopher is the soul to this masterpiece i became so with his performance i could feel my heart pounding the of the movie still moves me to this day his portrayal of john was oscar worthy as he should have been nominated for it'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START this movie is horrible you won't believe this hunk of junk is even a movie was better then this and was pretty frigging bad too a bunch of stupid teens crash in a desert find an old run down bungalow and end up fending off horrifically badly stop motion animated spiders pardon my french but the acting was bad as hell the person who wrote this probably didn't even know what a spider is because he had the spiders living in a colony serving an alien queen ripoff queen spider spiders do not live in colonies this movie is a piece of crud at the end the marines suddenly pop out of no where and kill all the spider without even being called if you see a copy of this movie at a video store it in gasoline and throw a match at it\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[6]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START bride of chucky starts late one night as officer bob bailey vince sneaks into the evidence room at his police station amongst all the horror film in joke props he steals the remains of the chucky doll that serial killer charles lee ray possessed way back in the original child's play 1988 he drives the remains to an isolated area where ray's ex girlfriend tiffany jennifer tilly slashes bailey's throat takes the remains back to her trailer there tiffany stitches staples chucky voiced by brad dourif back together again using a 'voodoo for book brings him back to murderous life thing don't go as tiffany had hoped chucky turns out not to be the man of her dreams after all so she locks him in a play pen at which chucky is less than happy while tiffany takes a bath chucky escapes electrocutes her using that book brings her back to life in the shape of a female doll dressed as a bride neither want to be stuck in plastic bodies have to work together to get to a cemetery in new jersey where ray's natural body had been buried with the amulet needed to switch their spirits back into human bodies the bodies of tiffany's neighbour jesse nick his girlfriend jade katherine heigl who are both on the run from corrupt uncle chief of police warren kincaid john ritter will do nicely br br directed by ronny yu i love bride of chucky the script by don mancini is great fun very fast moving highly entertaining references plenty of other horror film with good affection from the opening sequence where we see jason voorhees hockey mask from the friday the 13th films freddy krueger's razor blade glove from the a nightmare on elm street series michael myers mask from the halloween franchise to the clips used from bride of frankenstein 1935 when it virtually recreates the same scene bride of chucky never takes itself seriously which is just as well there are lots of one liners self referential gags that scream 1996 made trendy a few years earlier it doesn't seem afraid to poke fun at itself the horror genre in general i love the scene when jesse jade are having a clichéd slushy romantic conversation that chucky hears he makes funny derogatory comments gestures throughout that's not to say that there isn't a damn good film in there as well because there most certainly is director yu manages to create good atmosphere a real sense of fun both human plastic sets of characters are likable shine as each pair suffer their own sets of domestic problems that the trail of corpses that they are leaving behind would obviously cause technically bride of chucky is great for the most part has that big budget polish about it at about 25 000 000 i should hope so the only thing that i will say is that some of the puppet effects by kevin are a little stiff unconvincing i can't remember any cgi scenes in bride of chucky either thankfully the film doesn't neglect the blood gore with a cool slit throat nails blasted into someone's face in presumably a hellraiser 1987 homage people impaled on shards of glass someone being obliterated by a huge truck a ripped off lip piercing various stabbings gunshots the acting is pretty good dourif as chucky is very funny as he spouts the one liners out i also like the scenes with tiffany at the beginning find her very sexy when she's wearing all that fetish gear i can't be the only one surely i personally think bride of chucky is a fantastic film total entertainment from start to finish great humour horror in equal measure at only 85 minutes long it never becomes boring or dull a personal favourite of mine watch it as soon as you can\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.920050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.972661</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.931269</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.972241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.940057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.930902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.905394</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.924582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.916405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.987023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_hat  y\n",
       "21   0.920050  0\n",
       "25   0.972661  0\n",
       "95   0.931269  0\n",
       "143  0.972241  0\n",
       "150  0.940057  0\n",
       "204  0.930902  0\n",
       "258  0.905394  0\n",
       "304  0.924582  0\n",
       "470  0.916405  0\n",
       "489  0.987023  0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of errors in the classification\n",
    "ydf[(ydf.y == 0) & (ydf.y_hat > 0.9)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START committed doom and peter goes across the pond to take on the american justice system circa 1971 with this priceless piece of zeitgeist paranoia that leans so far left it falls over constantly is pure tourist as he assembles this our gang tragedy with cliché freaks hippies and black revolutionaries pitted against trigger happy cops and military and a kangaroo court tribunal made up of disapproving calcified adults making poor fashion statements talk about a revolution br br in punishment park we have radical youth versus corrupt system as dissenters convicted of crimes are given the choice of imprisonment or a three day trek across punishment park death valley and freedom of course the law enforcement officials monitoring their journey aren't about to play fair and combined with the stifling heat the fate of our protagonists looks sealed br br punishment park has elements of kafka in setting as well as theme trials are held under a large canvas tent where shackled prisoners shout defiance at a hardcore love it or leave it group of such as members of silent majority for a peaceful america who snarl back neither group spends much time listening to the other and the proceedings sometime takes on a teen parent battle over the keys to the car look mostly its just one side saying what's wrong with america the other saying what's right with no one offering solutions for change meanwhile the punishment park martyrs stumble endlessly about the dessert while cops with guns act like twelve year olds it kind of has the look and feel of some of my 70's college film making class when we were younger and knew more then than we do now br br peter has always been on the side of the underdog and the common man against what he perceives as a corrupt powerful few was a strong indictment of military atrocity in 18th century scotland that still resonates war game is a raw sobering look at nuclear aftermath that should be required viewing for all punishment park has its value as well but for other than intended reason vision today is a textbook example of the left in full tilt counter culture 70s paranoia and given the times vietnam kent state the chicago 7 such strident hysteria seemed not that great a distance from the truth but 35 years later the fever has subsided and punishment park with it's unrestrained narrow viewpoint is a pretty silly ride\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[25]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.061022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.048486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>0.081084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.054241</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.085272</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.060633</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0.063169</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>0.036033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.045404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>0.031759</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_hat  y\n",
       "151  0.061022  1\n",
       "239  0.048486  1\n",
       "426  0.081084  1\n",
       "543  0.054241  1\n",
       "602  0.085272  1\n",
       "732  0.060633  1\n",
       "926  0.063169  1\n",
       "927  0.036033  1\n",
       "951  0.045404  1\n",
       "961  0.031759  1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positives but classified as negative\n",
    "ydf[(ydf.y == 1) & (ydf.y_hat < 0.1)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"START i saw it in europe plex great movie br br this film is an exploration of the spirit and the flesh in modern times protagonist jim kirk drives an unwieldy rv across america stopping often to fill his gas guzzling tank he is middle aged and confused he fuels his thick diabetic body with cups of coffee and radio chatter he is the flesh agitated and sometimes spaced out fairly oblivious to the growing tension around him but feeling it as of discomfort br br the spirit the film through speeches and other sounds as well as what appears and goes by in the visual field the spirit eventually collides with the flesh and kirk goes down unable to comprehend what has happened to him he's been in denial about just how bad things have become due to he of all of us because we are all focused on the needs and desires of our flesh we're all in the same denial and so we like kirk are in danger of going down and being blown away by desert sands just like him\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(index_word[id] for id in all_x_valid[927]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is still room for improvement of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
